{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Smirnova_HW3_language_models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8-zdEmG1LTse"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wksmirnowa/deeplearning_homeworks/blob/master/Smirnova_HW3_language_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5OH7_1oLTsC"
      },
      "source": [
        "# Туториал по языковым моделям на базе RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7KQ1n0ULTsE"
      },
      "source": [
        "# # библиотека для BPE токенизации\n",
        "# # https://github.com/VKCOM/YouTokenToMe\n",
        "# !pip install youtokentome"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_SAxcHNijZI",
        "outputId": "0d1cfbd0-4ce2-45d8-fe52-286bd0d0c2a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V86TIrcBiUzM",
        "outputId": "8ed655db-7561-4ec4-aade-14b385df3792"
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\r\u001b[K     |▏                               | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 23.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 26.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 20.3MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 14.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 14.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 14.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 15.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 16.8MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 14.8MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153kB 14.8MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204kB 14.8MB/s eta 0:00:01\r\u001b[K     |████                            | 215kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 266kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 296kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 317kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 327kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 368kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 378kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 399kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 430kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 440kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 471kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 512kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 542kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 552kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 593kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 614kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 624kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 655kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 665kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 686kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 727kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 737kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 757kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 768kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 778kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 798kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 808kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 829kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 839kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 849kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 870kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 880kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 890kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 901kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 921kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 942kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 952kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 972kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 983kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 993kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogqPPjMZifTb",
        "outputId": "2b533c2a-465c-46c3-90cb-2bd4ff631235"
      },
      "source": [
        "!unzip /content/drive/MyDrive/dl_hw3/unsupervised.csv.zip\n",
        "!unzip /content/drive/MyDrive/dl_hw3/qa_data.jsonl.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/dl_hw3/unsupervised.csv.zip\n",
            "  inflating: unsupervised.csv        \n",
            "Archive:  /content/drive/MyDrive/dl_hw3/qa_data.jsonl.zip\n",
            "  inflating: qa_data.jsonl           \n",
            "  inflating: __MACOSX/._qa_data.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdMSLtLtLTsF"
      },
      "source": [
        "### Импортирование библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgEvwqCMLTsF"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import youtokentome as yttm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stmr5ycDLTsG"
      },
      "source": [
        "# для языковой модели мы будем использовать неразмеченные вопросы\n",
        "questions = pd.read_csv('unsupervised.csv')\n",
        "questions.question = questions.question.map(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YLbQOwcLTsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "abd742ba-17bc-4e79-dcd5-1bbe369ea66b"
      },
      "source": [
        "questions.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>положено ли пособие опекаемому ребенку, обучаю...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>где скачать прогу для записи видео онлайн. зар...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>физика амперы метрология помогите</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>имеет ли многодетная семья \"скидку\" на услуги ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>пенсия по инвалидности и старости...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>назовите несколько инженерных специальностей, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>в ваших iq тестах есть вопросы на знание унита...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>какие обязанности у уборщицы в отделении реани...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>что с работой уходить или оставаться?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>как из корня имбиря выжать сок ??(чтоб чуток р...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question\n",
              "0  положено ли пособие опекаемому ребенку, обучаю...\n",
              "1  где скачать прогу для записи видео онлайн. зар...\n",
              "2                  физика амперы метрология помогите\n",
              "3  имеет ли многодетная семья \"скидку\" на услуги ...\n",
              "4               пенсия по инвалидности и старости...\n",
              "5  назовите несколько инженерных специальностей, ...\n",
              "6  в ваших iq тестах есть вопросы на знание унита...\n",
              "7  какие обязанности у уборщицы в отделении реани...\n",
              "8              что с работой уходить или оставаться?\n",
              "9  как из корня имбиря выжать сок ??(чтоб чуток р..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFi9fcKwLTsH"
      },
      "source": [
        "## Обучение BPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C62ED7M1LTsH"
      },
      "source": [
        "# # для \"обучения\" bpe модели нам нужно сохранить данные для обучения в отдельный файл\n",
        "# # где будут построчно храниться тексты\n",
        "# # раскомментируйте этот код, чтобы собрать такой файл\n",
        "# with open('for_bpe.txt', 'w', encoding='utf-8') as f:\n",
        "#     for que in questions.question:\n",
        "#         f.write(que + '\\n')\n",
        "        \n",
        "# параметры\n",
        "vocab_size = 30_000\n",
        "model_path = '/content/drive/MyDrive/dl_hw3/pretrained_bpe_lm.model'\n",
        "data_path = '/content/drive/MyDrive/dl_hw3/for_bpe.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQXXSF3TLTsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0660b2f-aba0-478d-e28d-aded48bdfb4b"
      },
      "source": [
        "# %%time\n",
        "# # обучаем\n",
        "# # раскомментируйте этот код, чтобы обучить bpe\n",
        "# yttm.BPE.train(data=data_path, vocab_size=vocab_size, model=model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.7 s, sys: 2.24 s, total: 27 s\n",
            "Wall time: 19.2 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<youtokentome.youtokentome.BPE at 0x7f554e7b8390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GG8jJIALTsI"
      },
      "source": [
        "# загружаем токенизатор\n",
        "tokenizer = yttm.BPE(model=model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM9N6P53LTsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fe632e-62b2-44c1-f3fb-b876324cced5"
      },
      "source": [
        "tokenizer.vocab()[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PAD>',\n",
              " '<UNK>',\n",
              " '<BOS>',\n",
              " '<EOS>',\n",
              " '▁',\n",
              " 'о',\n",
              " 'а',\n",
              " 'е',\n",
              " 'т',\n",
              " 'и',\n",
              " 'н',\n",
              " 'с',\n",
              " 'р',\n",
              " 'к',\n",
              " 'л']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo9fdJbzLTsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d96beab-3645-431d-ba9c-0340c94ee6cd"
      },
      "source": [
        "# пример токенизации с выводом на уровне сабвордов\n",
        "tokenizer.encode(list(questions.question[:2]), bos=True, eos=True, output_type=yttm.OutputType.SUBWORD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<BOS>',\n",
              "  '▁положено',\n",
              "  '▁ли',\n",
              "  '▁пособие',\n",
              "  '▁опека',\n",
              "  'емо',\n",
              "  'му',\n",
              "  '▁ребен',\n",
              "  'ку,',\n",
              "  '▁обуча',\n",
              "  'ющему',\n",
              "  'ся',\n",
              "  '▁в',\n",
              "  '▁колледже',\n",
              "  ',',\n",
              "  '▁после',\n",
              "  '▁18',\n",
              "  '▁лет?',\n",
              "  '<EOS>'],\n",
              " ['<BOS>',\n",
              "  '▁где',\n",
              "  '▁скачать',\n",
              "  '▁прогу',\n",
              "  '▁для',\n",
              "  '▁записи',\n",
              "  '▁видео',\n",
              "  '▁онлайн.',\n",
              "  '▁заранее',\n",
              "  '▁благодарен',\n",
              "  '!',\n",
              "  '<EOS>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VBBKjbQLTsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7684f4fd-85cd-4ffb-d6a3-6cf0e57c8815"
      },
      "source": [
        "# пример токенизации с выводом на уровне индексов\n",
        "# как раз это нам и понадобится\n",
        "tokenizer.encode(list(questions.question[:2]), bos=True, eos=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2,\n",
              "  17159,\n",
              "  1827,\n",
              "  6986,\n",
              "  22120,\n",
              "  3393,\n",
              "  1936,\n",
              "  2800,\n",
              "  2973,\n",
              "  16624,\n",
              "  9760,\n",
              "  1820,\n",
              "  1774,\n",
              "  10516,\n",
              "  31,\n",
              "  2083,\n",
              "  2866,\n",
              "  3228,\n",
              "  3],\n",
              " [2, 1960, 3076, 7139, 1907, 6317, 2264, 22772, 3441, 8381, 45, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udVIxvU2LTsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6d18dc-0012-4899-b301-9598aaa759af"
      },
      "source": [
        "# проверим нет ли пропусков\n",
        "questions.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bupHpuxaLTsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89ae8a0-4ef7-4bad-d515-057fd76ae3e7"
      },
      "source": [
        "# давайте токенизируем наш датасет\n",
        "# токенизирую батчами, потому что так быстрее\n",
        "# также в начало добавляем токен bos (begin of sentence)\n",
        "# и в конец токен eos (end of sentence)\n",
        "\n",
        "tokenized = []\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "for i_batch in tqdm(range(math.ceil(len(questions.question) / batch_size))):\n",
        "    \n",
        "    tokenized.extend(tokenizer.encode(\n",
        "        list(questions.question[i_batch*batch_size:(i_batch+1)*batch_size]), bos=True, eos=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9905/9905 [00:25<00:00, 386.36it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdM2gw1uLTsL"
      },
      "source": [
        "### Формат данных\n",
        "\n",
        "По последовательности \"мама мыла\" нужно предсказать последовательность \"мыла раму\". Передаешь последовательность из двух слов в сетку \"мама мыла\" и получаешь предсказания такой же длины. Для каждого слова из исходной последовательности предсказать следующее слово.\n",
        "\n",
        "То есть по слову \"мама\" предсказать \"мыла\", а по слову \"мыла\" при условии, что предыдущее слово было \"мама\", предсказать следующее слово \"раму\". Вот именно это понятие \"при условии, что предыдущее слово было\" реализует RNN за счет памяти от состояния к состоянию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK4O5Wm-LTsL"
      },
      "source": [
        "sequence = 'чем бы мне заняться на выходных'.split()\n",
        "\n",
        "source_sequence = ['bos'] + sequence\n",
        "target_sequence = sequence + ['eos']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkUm09L7LTsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b5b31d-dfc0-4b8d-f92b-3a4a7206095c"
      },
      "source": [
        "for n in range(len(source_sequence)):\n",
        "    print(f'По токену \"{source_sequence[n]}\" предсказываем токен \"{target_sequence[n]}\"')\n",
        "    print('Или с точки зрения rnn')\n",
        "    message = f'По токену \"{source_sequence[n]}\" при условии того, что в памяти есть {source_sequence[:n]}'\n",
        "    message += f' предсказываем токен \"{target_sequence[n]}\"'\n",
        "    print(message)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "По токену \"bos\" предсказываем токен \"чем\"\n",
            "Или с точки зрения rnn\n",
            "По токену \"bos\" при условии того, что в памяти есть [] предсказываем токен \"чем\"\n",
            "\n",
            "По токену \"чем\" предсказываем токен \"бы\"\n",
            "Или с точки зрения rnn\n",
            "По токену \"чем\" при условии того, что в памяти есть ['bos'] предсказываем токен \"бы\"\n",
            "\n",
            "По токену \"бы\" предсказываем токен \"мне\"\n",
            "Или с точки зрения rnn\n",
            "По токену \"бы\" при условии того, что в памяти есть ['bos', 'чем'] предсказываем токен \"мне\"\n",
            "\n",
            "По токену \"мне\" предсказываем токен \"заняться\"\n",
            "Или с точки зрения rnn\n",
            "По токену \"мне\" при условии того, что в памяти есть ['bos', 'чем', 'бы'] предсказываем токен \"заняться\"\n",
            "\n",
            "По токену \"заняться\" предсказываем токен \"на\"\n",
            "Или с точки зрения rnn\n",
            "По токену \"заняться\" при условии того, что в памяти есть ['bos', 'чем', 'бы', 'мне'] предсказываем токен \"на\"\n",
            "\n",
            "По токену \"на\" предсказываем токен \"выходных\"\n",
            "Или с точки зрения rnn\n",
            "По токену \"на\" при условии того, что в памяти есть ['bos', 'чем', 'бы', 'мне', 'заняться'] предсказываем токен \"выходных\"\n",
            "\n",
            "По токену \"выходных\" предсказываем токен \"eos\"\n",
            "Или с точки зрения rnn\n",
            "По токену \"выходных\" при условии того, что в памяти есть ['bos', 'чем', 'бы', 'мне', 'заняться', 'на'] предсказываем токен \"eos\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTnDMru_LTsM"
      },
      "source": [
        "class LanguageModelData(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, data, max_len, pad_index, eos_index):\n",
        "        \n",
        "        self.data = data\n",
        "        \n",
        "        self.max_len = max_len\n",
        "        \n",
        "        self.pad_index = pad_index\n",
        "        self.eos_index = eos_index\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        sequence = self.data[index][:self.max_len]\n",
        "        \n",
        "        # исходная последовательность\n",
        "        x = sequence[:]\n",
        "        # нужно предсказать смещенную последовательность\n",
        "        y = sequence[1:] + [self.eos_index]\n",
        "        \n",
        "        assert len(x) == len(y)\n",
        "        \n",
        "        pads = [self.pad_index] * (self.max_len - len(x))\n",
        "        \n",
        "        x = torch.tensor(x + pads).long()\n",
        "        y = torch.tensor(y + pads).long()\n",
        "        \n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg7YcwalLTsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40718f15-09fc-47d7-e965-8bd77a1f4f55"
      },
      "source": [
        "# надо выбрать максимальную длину\n",
        "lengths = np.array([len(x) for x in tokenized])\n",
        "np.percentile(lengths, q=95)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuTYiDf7LTsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb3ad49-3011-42ad-85e0-d3e41fe24fbe"
      },
      "source": [
        "tokenizer.vocab()[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PAD>',\n",
              " '<UNK>',\n",
              " '<BOS>',\n",
              " '<EOS>',\n",
              " '▁',\n",
              " 'о',\n",
              " 'а',\n",
              " 'е',\n",
              " 'т',\n",
              " 'и',\n",
              " 'н',\n",
              " 'с',\n",
              " 'р',\n",
              " 'к',\n",
              " 'л']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLCQb3wSLTsN"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "max_len = 32\n",
        "\n",
        "pad_index = 0\n",
        "eos_index = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xxE018dLTsO"
      },
      "source": [
        "random.shuffle(tokenized)\n",
        "\n",
        "validation_start_index = int(len(tokenized) * 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPaQ3NbALTsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8c58ae-fbe5-4568-8da7-ab0e3b54d648"
      },
      "source": [
        "train_dataset = LanguageModelData(data=tokenized[:-validation_start_index], max_len=max_len, \n",
        "                                  pad_index=pad_index, eos_index=eos_index)\n",
        "validation_dataset = LanguageModelData(data=tokenized[-validation_start_index:], max_len=max_len,\n",
        "                                       pad_index=pad_index, eos_index=eos_index)\n",
        "\n",
        "len(train_dataset), len(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2408671, 126772)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJJHG4GrLTsP"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APnCgj2mLTsP"
      },
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCI0TUldLTsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f048cae2-e76f-4c1a-fd47-94d847aedf60"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2,  3164, 26893,  ...,     0,     0,     0],\n",
              "        [    2,  1956,  2073,  ...,     0,     0,     0],\n",
              "        [    2,  3483,  2836,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2,  3153,  1827,  ...,     0,     0,     0],\n",
              "        [    2,  1866, 14823,  ...,     0,     0,     0],\n",
              "        [    2,  1774,  2735,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwcejCdGLTsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7c1a31-2f19-48c2-c0c6-5b12076644a3"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3164, 26893,  1784,  ...,     0,     0,     0],\n",
              "        [ 1956,  2073, 26667,  ...,     0,     0,     0],\n",
              "        [ 3483,  2836, 23695,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [ 3153,  1827,  8863,  ...,     0,     0,     0],\n",
              "        [ 1866, 14823, 28698,  ...,     0,     0,     0],\n",
              "        [ 1774,  2735,  8673,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx8xyG5KLTsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6592a32-67a5-4724-a6f3-b0f7dd2b36eb"
      },
      "source": [
        "# первое слово в source равняется нулевому слову в target\n",
        "x[:, 1] == y[:, 0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfZXdwRGLTsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153cfbdf-f384-4561-e25c-238bec850ac1"
      },
      "source": [
        "# пробежимся по итератору, чтобы убедиться что ничего не падает и он работает достаточно быстро\n",
        "\n",
        "progress_bar = tqdm(total=len(validation_loader.dataset), desc='Testing')\n",
        "\n",
        "for x, y in validation_loader:\n",
        "    progress_bar.update(x.size(0))\n",
        "    \n",
        "progress_bar.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 126772/126772 [00:02<00:00, 54376.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxyn6-NmLTsQ"
      },
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, model_dim, num_layers, dropout, padding_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # просто эмбеддинги\n",
        "        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, \n",
        "                                                  embedding_dim=embedding_dim,\n",
        "                                                  padding_idx=padding_idx)\n",
        "        \n",
        "        # просто lstm\n",
        "        self.lstm = torch.nn.LSTM(input_size=embedding_dim, \n",
        "                                  hidden_size=model_dim,\n",
        "                                  num_layers=num_layers, \n",
        "                                  dropout=0.3,\n",
        "                                  batch_first=True)\n",
        "        \n",
        "        # выходная матрица эмбеддингов\n",
        "        # количество выходных фичей равно размеру словаря\n",
        "        # то есть это задача мультиклассовой классификации, но только классов очень много\n",
        "        self.language_model_head = torch.nn.Linear(in_features=model_dim,\n",
        "                                                   out_features=vocab_size,\n",
        "                                                   bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.embedding_layer(x)\n",
        "        \n",
        "        x, _ = self.lstm(x)\n",
        "        \n",
        "        # к каждому элементу последовательности применяется выходная матрица эмбеддингов, \n",
        "        # которая переводит вектор lstm в предсказание конкретного слова\n",
        "        x = self.language_model_head(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffnE75_2LTsR"
      },
      "source": [
        "###  Device\n",
        "\n",
        "Таким образом задается девайс, на котором мы будем обучаться. Мы можем указать либо гпу (вплоть до конкретной карты), либо цпу. В этой домашке нам обязательно понадобится гпу, так как на цпу обучение будет занимать слишко долгое время.\n",
        "\n",
        "Используйте для гпу такие сервисы:  \n",
        "Бесплатный: https://colab.research.google.com/  \n",
        "\n",
        "Почти бесплатный: https://vast.ai  \n",
        "Хороший выбор машины с гпу - 1080TI  \n",
        "Стоимость такой машины примерно 8 рублей в час"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf_8_zoILTsR"
      },
      "source": [
        "assert torch.cuda.is_available(), 'у вас не находится гпу'\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rID4dBuLTsR"
      },
      "source": [
        "embedding_dim = 128\n",
        "model_dim = 128\n",
        "num_layers = 2\n",
        "dropout = 0.35"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbHErT-KLTsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d3412e-0f92-44a5-b1a5-75fc0b94da9c"
      },
      "source": [
        "model = LanguageModel(vocab_size=vocab_size, embedding_dim=embedding_dim,\n",
        "                      model_dim=model_dim, num_layers=num_layers,\n",
        "                      dropout=dropout, padding_idx=pad_index)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding_layer): Embedding(30000, 128, padding_idx=0)\n",
              "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
              "  (language_model_head): Linear(in_features=128, out_features=30000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t28uAqUmLTsS"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2J5xsjiLTsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3914d186-4b84-429b-ab87-4b4e4daa9255"
      },
      "source": [
        "print(f'Количество обучаемых параметров в сети: {count_parameters(model):,}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество обучаемых параметров в сети: 7,944,192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l84yGt2wLTsT"
      },
      "source": [
        "x = x.to(device)\n",
        "y = y.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ5ILJtuLTsT"
      },
      "source": [
        "# проверим все ли корректно предсказывается\n",
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urilp4TzLTsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab38df85-5cf0-4141-ac65-fbfa663854ca"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([52, 32, 30000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92vcvrHYLTsU"
      },
      "source": [
        "# у нас есть тег eos (end of sentence), который есть в каждом тренировочном примере\n",
        "# мы не будем считать лосс для падов\n",
        "# вместо этого будем останавливать генерирование моделью в момент, когда она сгенерирует тег eos\n",
        "# \n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "optimizer = torch.optim.Adam(params=model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki8DspZkLTsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b448435f-060f-4668-bbe7-d2bc2d9303ba"
      },
      "source": [
        "# развернем все наши предсказания в один большой батч\n",
        "# наши предсказания и наши таргеты сохраняют свое местоположение\n",
        "# а пады не учитываются в расчете лосса\n",
        "pred.view(-1, pred.size(-1)).shape, y.view(-1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1664, 30000]), torch.Size([1664]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYksiO45LTsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e25172c-029d-4e21-ac58-dbcf55badb2f"
      },
      "source": [
        "# и за счет этого вот так просто можем посчитать лосс для всего батча и для всех таймстемпов\n",
        "\n",
        "loss = criterion(pred.view(-1, pred.size(-1)), y.view(-1))\n",
        "\n",
        "loss.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.308330535888672"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzzsK9G9LTsU"
      },
      "source": [
        "# функция для обучения одной эпохи\n",
        "# почти все как всегда\n",
        "\n",
        "def train(model, loader, criterion, optimizer, last_n_losses=500, verbose=True):\n",
        "    \n",
        "    losses = []\n",
        "\n",
        "    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Train')\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for x, y in loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        pred = model(x)\n",
        "\n",
        "        loss = criterion(pred.view(-1, pred.size(-1)), y.view(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
        "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])))\n",
        "\n",
        "        progress_bar.update()\n",
        "\n",
        "    progress_bar.close()\n",
        "    \n",
        "    return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCi3RA0CLTsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6e29da-182c-4de2-e28e-70f3489023a2"
      },
      "source": [
        "# обратите внимание, что будем тестироваться (именно коректность кода) на валидационном датасете\n",
        "# нам сейчас важно понять, что все работает\n",
        "# код не падает, лосс снижается\n",
        "# валидационный датасет сильно меньше тренировочного и давайте будем тестироваться (понять, что все работает) на нем\n",
        "epoch_losses = train(model, validation_loader, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1981/1981 [02:09<00:00, 15.32it/s, loss=7.39, perplexity=1.62e+3]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npYuq42eLTsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "outputId": "de419612-4d1b-49d6-8237-4110d141a881"
      },
      "source": [
        "plt.figure(figsize=(14, 14))\n",
        "plt.xlabel('Номер батча')\n",
        "plt.ylabel('Значение функции потерь')\n",
        "plt.title('Процесс обучения')\n",
        "plt.plot(epoch_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f550ec4de48>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x1008 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaSw0z45LTsV"
      },
      "source": [
        "# фукнция для расчета метрик на тесте\n",
        "\n",
        "def evaluate(model, loader, criterion, last_n_losses=500, verbose=True):\n",
        "    \n",
        "    losses = []\n",
        "\n",
        "    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Evaluate')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for x, y in loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(x)\n",
        "\n",
        "        loss = criterion(pred.view(-1, pred.size(-1)), y.view(-1))\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
        "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])))\n",
        "\n",
        "        progress_bar.update()\n",
        "\n",
        "    progress_bar.close()\n",
        "    \n",
        "    return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo8B9ibjLTsW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e5c7061e-e4d3-4740-90d9-a226c32afa33"
      },
      "source": [
        "val_losses = evaluate(model, validation_loader, criterion)\n",
        "f'Val loss - {np.mean(val_losses):.3f} perplexity - {np.exp(np.mean(val_losses)):.3f}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate: 100%|██████████| 1981/1981 [00:47<00:00, 41.78it/s, loss=7.13, perplexity=1.24e+3]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Val loss - 7.217 perplexity - 1363.014'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaf4uHhCLTsW"
      },
      "source": [
        "# это специальный дропаут для реккуретных сетей\n",
        "# хорошо это объясняется здесь: https://youtu.be/WLaAIYQHHMU?t=1093\n",
        "\n",
        "class SpatialDropout(torch.nn.Dropout2d):\n",
        "    \n",
        "    def __init__(self, p=0.5):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
        "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T)\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
        "        x = x.squeeze(2)  # (N, T, K)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqMEewdeLTsW"
      },
      "source": [
        "spatial_dropout = SpatialDropout()\n",
        "common_dropout = torch.nn.Dropout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGvEUv-1LTsW"
      },
      "source": [
        "# пусть у нас есть какой батч с размером батча 2 пример, 4 длиной последовательности и 8 размеров эмбеддинга\n",
        "z = torch.rand(2, 4, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3LQt4JQLTsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b076e0b-7e92-4db0-ac1b-5217bcbb5d3b"
      },
      "source": [
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.9683, 0.3060, 0.6970, 0.3073, 0.1638, 0.6806],\n",
              "         [0.1325, 0.8076, 0.6036, 0.7027, 0.7737, 0.4588],\n",
              "         [0.3776, 0.2113, 0.8033, 0.8053, 0.6633, 0.0500],\n",
              "         [0.5396, 0.7563, 0.8308, 0.8604, 0.8190, 0.8542]],\n",
              "\n",
              "        [[0.2814, 0.6582, 0.7470, 0.4987, 0.1327, 0.3306],\n",
              "         [0.8091, 0.7660, 0.8605, 0.0754, 0.7066, 0.5146],\n",
              "         [0.4554, 0.8394, 0.9739, 0.3090, 0.8913, 0.2687],\n",
              "         [0.6884, 0.2095, 0.0814, 0.3441, 0.1012, 0.1917]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYod4x32LTsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515cb79c-2ef1-4539-aeb8-771af5c95243"
      },
      "source": [
        "# этот дропаут выкидывает значения для какого-либо размерности для каждого элемента последовательности\n",
        "# чем это лучше обычного дропаута в реккуретных сетях можно посмотреть опять-таки здесь: https://youtu.be/WLaAIYQHHMU?t=1093\n",
        "spatial_dropout(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.9365, 0.6121, 0.0000, 0.0000, 0.3277, 1.3611],\n",
              "         [0.2651, 1.6152, 0.0000, 0.0000, 1.5475, 0.9176],\n",
              "         [0.7551, 0.4226, 0.0000, 0.0000, 1.3266, 0.0999],\n",
              "         [1.0792, 1.5125, 0.0000, 0.0000, 1.6380, 1.7084]],\n",
              "\n",
              "        [[0.5627, 1.3164, 0.0000, 0.0000, 0.0000, 0.6613],\n",
              "         [1.6183, 1.5320, 0.0000, 0.0000, 0.0000, 1.0292],\n",
              "         [0.9108, 1.6789, 0.0000, 0.0000, 0.0000, 0.5374],\n",
              "         [1.3767, 0.4189, 0.0000, 0.0000, 0.0000, 0.3834]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdd-dW4mLTsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2189c740-9fd2-406d-a8f9-9cadf1742f16"
      },
      "source": [
        "# а вот так работает простой дропаут\n",
        "common_dropout(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.6121, 1.3941, 0.6147, 0.0000, 0.0000],\n",
              "         [0.2651, 1.6152, 1.2073, 1.4054, 0.0000, 0.9176],\n",
              "         [0.0000, 0.4226, 1.6067, 0.0000, 1.3266, 0.0000],\n",
              "         [1.0792, 0.0000, 1.6616, 1.7209, 0.0000, 0.0000]],\n",
              "\n",
              "        [[0.5627, 1.3164, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [1.6183, 1.5320, 0.0000, 0.0000, 1.4131, 0.0000],\n",
              "         [0.0000, 1.6789, 0.0000, 0.6181, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "906inYlgLTsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13485f56-368f-4301-d1df-e21e2a90fb49"
      },
      "source": [
        "# заметим, что входные и выходные эмбеддинги имеют одинаковую размерность\n",
        "# точней они могут иметь не одинаковую, но мы можем сделать ее одинаковой\n",
        "# и мы можем сделать такую вещь как weight tying\n",
        "# когда выходящие эмбеддинги шарят веса с входящими\n",
        "# это полезно делать, потому что, как правило, матрица эмбеддингов занимает самую большую долю всех весов в сети\n",
        "# а в языковой модели у нас целых 2 такие матрицы\n",
        "# давайте выходной слой будет ссылаться (шарить) на веса входящего слоя эмбеддингов\n",
        "\n",
        "model.embedding_layer.weight.shape, model.language_model_head.weight.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([30000, 128]), torch.Size([30000, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIe15ERELTsY"
      },
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, model_dim, num_layers,\n",
        "                 padding_idx, dropout=0.35, weight_tying=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size,\n",
        "                                                  embedding_dim=embedding_dim, padding_idx=padding_idx)\n",
        "        \n",
        "        self.embedding_dropout = SpatialDropout(p=dropout)\n",
        "        \n",
        "        self.lstm = torch.nn.LSTM(input_size=embedding_dim, hidden_size=model_dim, \n",
        "                                  num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        \n",
        "        self.language_model_head = torch.nn.Linear(in_features=model_dim, out_features=vocab_size, bias=False)\n",
        "        \n",
        "        # как раз здесь задаем, чтобы веса входящего и выходящего слоя эмбеддингов шарились\n",
        "        if weight_tying and embedding_dim == model_dim:\n",
        "            self.language_model_head.weight = self.embedding_layer.weight\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.embedding_layer(x)\n",
        "        \n",
        "        x = self.embedding_dropout(x)\n",
        "        \n",
        "        x, _ = self.lstm(x)\n",
        "        \n",
        "        x = self.language_model_head(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Xmla2eLTsY"
      },
      "source": [
        "model = LanguageModel(vocab_size=vocab_size, embedding_dim=embedding_dim, model_dim=model_dim, \n",
        "                      num_layers=num_layers, dropout=dropout, padding_idx=pad_index, weight_tying=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5AaRPqbLTsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364e7544-a093-4408-fe39-eab09aa7ad94"
      },
      "source": [
        "print(f'Количество обучаемых параметров в сети: {count_parameters(model):,}')\n",
        "print('Их стало сильно меньше за счет weight tying!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество обучаемых параметров в сети: 4,104,192\n",
            "Их стало сильно меньше за счет weight tying!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwI-Am6qLTsZ"
      },
      "source": [
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCuT0k4cLTsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db4f1ed-25c7-4d53-c803-95a4bb433a42"
      },
      "source": [
        "epoch_losses = train(model, validation_loader, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1981/1981 [02:05<00:00, 15.75it/s, loss=7.82, perplexity=2.48e+3]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq4WW_brLTsa"
      },
      "source": [
        "### Метрики стали хуже, но на долгосрочную переспективу они будут лучше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E8o_SpBLTsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524a16a8-e6bc-4e46-dc40-275d6c7fc4ea"
      },
      "source": [
        "# вот что происходит внутри сети\n",
        "\n",
        "# переключаем в режим предсказаний\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    emb = model.embedding_layer(x)\n",
        "\n",
        "    emb = model.embedding_dropout(emb)\n",
        "\n",
        "    lstm_out, _ = model.lstm(emb)\n",
        "\n",
        "    prediction = model.language_model_head(lstm_out)\n",
        "    \n",
        "# переключаем в режим тренировки обратно\n",
        "model.train()\n",
        "\n",
        "# считаем функцию потерь\n",
        "criterion(prediction.view(-1, pred.size(-1)), y.view(-1)).item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.709980010986328"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BntMcvpLTsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205d72f4-61aa-4cf4-e87e-7372b89e2c12"
      },
      "source": [
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([52, 32, 30000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3b5-7EKLTsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f6647b-9694-40f7-86ff-f0c182c043ab"
      },
      "source": [
        "# давайте распишем подробнее\n",
        "# как lstm итерируется по каждому таймстемпу\n",
        "\n",
        "# переключаем в режим предсказаний\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # массив для предсказаний нашей последовательности\n",
        "    pred = []\n",
        "    \n",
        "    # инициализация памяти для lstm\n",
        "    zeros = torch.zeros(num_layers, x.size(0), model_dim, dtype=torch.float32, device=x.device)\n",
        "    hx = (zeros, zeros)\n",
        "    \n",
        "    # цикл по временной последовательности\n",
        "    for timestamp in range(x.size(1)):\n",
        "        \n",
        "        # выбираем на каждому шаге очередной токен и добавляем размерность будто у нас предложения из 1 токена\n",
        "        current_token = x[:, timestamp].unsqueeze(1)\n",
        "        \n",
        "        emb = model.embedding_layer(current_token)\n",
        "\n",
        "        emb = model.embedding_dropout(emb)\n",
        "\n",
        "        # рассчитываем предикт lstm и обновляем память\n",
        "        lstm_out, hx = model.lstm(emb, hx)\n",
        "\n",
        "        # предсказываем следующий токен\n",
        "        next_token_prediction = model.language_model_head(lstm_out)\n",
        "        \n",
        "        # добавляем в массив предсказаний\n",
        "        pred.append(next_token_prediction)\n",
        "       \n",
        "    # конкатерируем в последовательность\n",
        "    pred = torch.cat(pred, dim=1)\n",
        "    \n",
        "# переключаем в режим тренировки обратно\n",
        "model.train()\n",
        "    \n",
        "# считаем функцию потерь\n",
        "criterion(pred.view(-1, pred.size(-1)), y.view(-1)).item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.709980010986328"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t83BrcqSLTsb"
      },
      "source": [
        "### Генерация\n",
        "В конце туториала мы будем использовать текст, чтобы его продолжить, а сейчас используем на вход только токен bos (begin of sentence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raDOlTooLTsc"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    pred = []\n",
        "    \n",
        "    zeros = torch.zeros(num_layers, x.size(0), model_dim, dtype=torch.float32, device=x.device)\n",
        "    hx = (zeros, zeros)\n",
        "    \n",
        "    # семплируем начальный токен bos для каждого предложения\n",
        "    current_token = x[:, 0].unsqueeze(1)\n",
        "    \n",
        "    for timestamp in range(x.size(1)):\n",
        "        \n",
        "        # пока все то же самое\n",
        "        emb = model.embedding_layer(current_token)\n",
        "\n",
        "        emb = model.embedding_dropout(emb)\n",
        "\n",
        "        lstm_out, hx = model.lstm(emb, hx)\n",
        "\n",
        "        next_token_prediction = model.language_model_head(lstm_out)\n",
        "        \n",
        "        pred.append(next_token_prediction)\n",
        "        \n",
        "        # но вот здесь мы семплируем предсказания сети и передадим это как текущий токен для следующего таймстемпа\n",
        "        current_token = next_token_prediction.argmax(dim=2)\n",
        "        \n",
        "    pred = torch.cat(pred, dim=1)\n",
        "    \n",
        "model.train()\n",
        "    \n",
        "tokens = pred.argmax(dim=-1).detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhJQ8A0qLTsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c89521-34e1-477a-acd5-a5940e520847"
      },
      "source": [
        "# вот что мы предсказали\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1797, 2395, 1774, ...,    3,    3,    3],\n",
              "       [1797, 2395, 1774, ...,    3,    3,    3],\n",
              "       [1797, 2395, 1774, ...,    3,    3,    3],\n",
              "       ...,\n",
              "       [1797, 2395, 1774, ...,    3,    3,    3],\n",
              "       [1797, 2395, 1774, ...,    3,    3,    3],\n",
              "       [1797, 2395, 1774, ...,    3,    3,    3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhsZBJE3LTsd"
      },
      "source": [
        "predicted_texts = tokenizer.decode(tokens.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yDjycBLTsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2503e47-d8cb-46bd-9485-409bafca0048"
      },
      "source": [
        "for n in range(5):\n",
        "    print(predicted_texts[n][:predicted_texts[n].index('<EOS>')])\n",
        "    \n",
        "# они все одинаковые, потому что на вход подается один и тот же токен <BOS>, а веса модели зафиксированы"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "как называется в россии\n",
            "как называется в россии\n",
            "как называется в россии\n",
            "как называется в россии\n",
            "как называется в россии\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-zdEmG1LTse"
      },
      "source": [
        "### Результаты генерации\n",
        "\n",
        "Достаточно неплохо для 30 секунд обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH4v9PmiLTse"
      },
      "source": [
        "### Sequence bucketing\n",
        "\n",
        "Наша модель никак не привязана к длине последовательности, привязана только лишь читалка данных и мы искуственно ограничиваем длину наших примеров.\n",
        "\n",
        "Мы можем обрубать длины примеров в нашем батче до максимальной длины в батче, но батче могут быть 63 примера с длиной, допустим, 10 и 1 пример с длиной в 31 слова. В этом случае мы обрубим длину только лишь на один токен и будем тратить лишнее время итерируясь по нулям, которые нам не нужны.\n",
        "\n",
        "Может стоит отсортировать датасет и идти от самого маленького к самому большому примеру или наоброт. Еще большая проблема, потому что, как минимум, предложения разной длины несут разный смысл. И наша сеть по мере обучения будет от эпохи к эпохе стараться адаптироваться то к маленьким, то к большим последовательностям. Это очень плохо.\n",
        "\n",
        "А давайте мы тогда составим наши батчи с примерно одинаковой длиной, зашафлим данные на уровне батче и будем итерироваться по батчам с одинаковой длиной. То есть у нас будет то длиный батч, то короткий, то средний, то есть мы не будем привязываться к длине.\n",
        "\n",
        "Ниже достаточно простой (но не единственный и далеко не оптимальный) способ это сделать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6NXVtyULTse"
      },
      "source": [
        "tokenized = sorted(tokenized, key=lambda x: len(x))\n",
        "\n",
        "# сделаем батч побольше\n",
        "batch_size = 256\n",
        "\n",
        "batches = []\n",
        "\n",
        "for i_batch in range(math.ceil(len(tokenized) / batch_size)):\n",
        "    \n",
        "    batches.append(tokenized[i_batch*batch_size:(i_batch+1)*batch_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev2Aw6peLTsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8be38e-0bf1-4674-ee11-022603fff90b"
      },
      "source": [
        "len(batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9905"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-grDD00nLTsf"
      },
      "source": [
        "random.shuffle(batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdDM15eTLTsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ced8a92-eaf3-4dc2-bc5e-fb192f67e533"
      },
      "source": [
        "[len(sample) for sample in random.choice(batches)][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 6, 6, 6, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g15x9SARLTsf"
      },
      "source": [
        "class SequenceBucketingData(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, data, max_len, pad_index, eos_index):\n",
        "        \n",
        "        self.data = data\n",
        "        \n",
        "        self.max_len = max_len\n",
        "        \n",
        "        self.pad_index = pad_index\n",
        "        self.eos_index = eos_index\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def prepare_sample(self, sequence, max_len):\n",
        "        \n",
        "        sequence = sequence[:max_len]\n",
        "        \n",
        "        x = sequence[:]\n",
        "        y = sequence[1:] + [self.eos_index]\n",
        "        \n",
        "        assert len(x) == len(y)\n",
        "        \n",
        "        pads = [self.pad_index] * (max_len - len(x))\n",
        "        \n",
        "        x += pads\n",
        "        y += pads\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        batch = self.data[index]\n",
        "        \n",
        "        max_len = min([self.max_len, max([len(sample) for sample in batch])])\n",
        "        \n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        \n",
        "        for sample in batch:\n",
        "            x, y = self.prepare_sample(sample, max_len)\n",
        "            batch_x.append(x)\n",
        "            batch_y.append(y)\n",
        "        \n",
        "        batch_x = torch.tensor(batch_x).long()\n",
        "        batch_y = torch.tensor(batch_y).long()\n",
        "        \n",
        "        return batch_x, batch_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8fCF8rvLTsf"
      },
      "source": [
        "validation_start_index = int(len(batches) * 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQoBEr6ILTsg"
      },
      "source": [
        "train_dataset = SequenceBucketingData(batches[:-validation_start_index], max_len, pad_index, eos_index)\n",
        "validation_dataset = SequenceBucketingData(batches[-validation_start_index:], max_len, pad_index, eos_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1B_PIJOLTsg"
      },
      "source": [
        "# чтобы убрать лишнюю размерность\n",
        "\n",
        "def collate_fn(x):\n",
        "    \n",
        "    x, y = x[0]\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtE4vbidLTsg"
      },
      "source": [
        "# ставим batch_size=1 потому что датасет уже отдает батч\n",
        "# добавим shuffle=True\n",
        "# за счет этого флага каждую эпоху датасет перемешивается\n",
        "\n",
        "# collate_fn это функция, с помощью которой можно задать свою логику сборки батча\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                           batch_size=1,\n",
        "                                           collate_fn=collate_fn,\n",
        "                                           shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset,\n",
        "                                                batch_size=1,\n",
        "                                                collate_fn=collate_fn, \n",
        "                                                shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddD5xjCLLTsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7023eafe-e627-4714-bf80-33f6f7cfde89"
      },
      "source": [
        "# пробежимся по итератору, чтобы убедиться что ничего не падает и он работает достаточно быстро\n",
        "\n",
        "progress_bar = tqdm(total=len(validation_loader.dataset), desc='Testing')\n",
        "\n",
        "for x, y in validation_loader:\n",
        "    progress_bar.update()\n",
        "    \n",
        "progress_bar.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 495/495 [00:00<00:00, 1011.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPX7gHCiLTsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead5feb8-e781-4231-af2a-aa5813658edd"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2,  2039,  3472,  ...,  1841, 10132, 29484],\n",
              "        [    2,  1816,  7824,  ...,  2714,  7359,  2249],\n",
              "        [    2,  1991,  2702,  ...,  2088,  1840, 14994],\n",
              "        ...,\n",
              "        [    2,  1816,  2176,  ...,  1883,  3543,  2057],\n",
              "        [    2,  2004,  9740,  ...,  2317,  7053,  4044],\n",
              "        [    2,  1779, 21478,  ...,  2140,  2009,  5980]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmqvJmgrLTsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a4493b-8871-4f9c-e30d-22ef21421603"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2039,  3472,  7009,  ..., 10132, 29484,     3],\n",
              "        [ 1816,  7824,  1774,  ...,  7359,  2249,     3],\n",
              "        [ 1991,  2702,  2059,  ...,  1840, 14994,     3],\n",
              "        ...,\n",
              "        [ 1816,  2176,  5956,  ...,  3543,  2057,     3],\n",
              "        [ 2004,  9740,  5362,  ...,  7053,  4044,     3],\n",
              "        [ 1779, 21478,  2446,  ...,  2009,  5980,     3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z9oC9d8LTsh"
      },
      "source": [
        "### Добавим в обучение gradient clipping\n",
        "\n",
        "Эта техника помогает меньше влиять взрыву градиента за счет того, что мы нормируем наши градиенты, если норма прошла какой-то порог. Обычные значения от 0 до 10. Чем меньше, тем сильнее влияние этой нормировки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22-nHAKNLTsh"
      },
      "source": [
        "def train(model, loader, criterion, optimizer, clip=3., last_n_losses=500, verbose=True):\n",
        "    \n",
        "    losses = []\n",
        "\n",
        "    progress_bar = tqdm(total=len(loader.dataset), disable=not verbose, desc='Train')\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for x, y in loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        pred = model(x)\n",
        "\n",
        "        loss = criterion(pred.view(-1, pred.size(-1)), y.view(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # рассчитали градиенты и клипаем их\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
        "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])))\n",
        "\n",
        "        progress_bar.update()\n",
        "\n",
        "    progress_bar.close()\n",
        "    \n",
        "    return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzPBB3o1LTsh"
      },
      "source": [
        "model = LanguageModel(vocab_size=vocab_size, embedding_dim=embedding_dim, model_dim=model_dim, \n",
        "                      num_layers=num_layers, padding_idx=pad_index, weight_tying=True)\n",
        "\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7rcy9vCLTsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc467bc-509f-424b-b7d5-1e007f444a1b"
      },
      "source": [
        "epoch_losses = train(model, validation_loader, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 495/495 [00:43<00:00, 11.37it/s, loss=8.35, perplexity=4.24e+3]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu9EQZL7LTsi"
      },
      "source": [
        "### Сильно ускорились \n",
        "\n",
        "### Все готово для того, чтобы начать обучение "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MJZ_xEgLTsi"
      },
      "source": [
        "embedding_dim = 512\n",
        "model_dim = 512\n",
        "num_layers = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjXE0TDxLTsi"
      },
      "source": [
        "vocab_size = 30_000\n",
        "pad_index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbxi5CC2LTsi"
      },
      "source": [
        "model = LanguageModel(vocab_size=vocab_size, embedding_dim=embedding_dim, model_dim=model_dim, \n",
        "                      num_layers=num_layers, padding_idx=pad_index, weight_tying=True)\n",
        "\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBa8tO7zLTsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe90a7e5-e6ab-4c9a-a425-67abb8b55c8d"
      },
      "source": [
        "print(f'Количество обучаемых параметров в сети: {count_parameters(model):,}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество обучаемых параметров в сети: 21,663,744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpPTz8o5LTsj"
      },
      "source": [
        "# # если вы перезапускаете обучение и хотите продолжить его\n",
        "# # то есть у вас должны уже быть эти стейт дикты\n",
        "\n",
        "# # подгружаем свою обученную модель\n",
        "# model.load_state_dict(torch.load('best_language_model_state_dict.pth'))\n",
        "\n",
        "# # загружаем (и соответственно во время тренировки сохраняем) оптимизатор (с той же эпохи)\n",
        "# # это нужно потому что в нем хранятся нужные статистики\n",
        "# # которые мы считали во время обучения, например, для моментума\n",
        "# optimizer.load_state_dict(torch.load('best_optimizer_state_dict.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDWl3ajaLTsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4254bf9b-2331-4b5b-de7d-48548ba4b788"
      },
      "source": [
        "# задайте сколько вам комфортно обучать модель по времени\n",
        "# в идеале пару часов\n",
        "epochs = 2\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "train_perplexities = []\n",
        "validation_perplexities = []\n",
        "\n",
        "best_validation_loss = 1e+6\n",
        "\n",
        "for n_epoch in range(1, epochs + 1):\n",
        "    \n",
        "    epoch_train_losses = train(model, train_loader, criterion, optimizer)\n",
        "    epoch_validation_losses = evaluate(model, validation_loader, criterion)\n",
        "    \n",
        "    mean_train_loss = np.mean(epoch_train_losses)\n",
        "    mean_validation_loss = np.mean(epoch_validation_losses)\n",
        "    \n",
        "    train_losses.append(epoch_train_losses)\n",
        "    train_perplexities.append(np.exp(mean_train_loss))\n",
        "    \n",
        "    validation_losses.append(epoch_validation_losses)\n",
        "    validation_perplexities.append(np.exp(mean_validation_loss))\n",
        "    \n",
        "    message = f'Epoch: {n_epoch}\\n'\n",
        "    message += f'Train: loss - {mean_train_loss:.4f} | perplexity - {train_perplexities[-1]:.3f}\\n'\n",
        "    message += f'Validation: loss - {mean_validation_loss:.4f} | perplexity - {validation_perplexities[-1]:.3f}'\n",
        "    \n",
        "    print(message)\n",
        "    \n",
        "    if mean_validation_loss < best_validation_loss:\n",
        "        \n",
        "        best_validation_loss = mean_validation_loss\n",
        "        \n",
        "        torch.save(model.state_dict(), f'best_language_model_state_dict.pth')\n",
        "        torch.save(optimizer.state_dict(), 'best_optimizer_state_dict.pth')\n",
        "        \n",
        "    else:\n",
        "        break\n",
        "        \n",
        "    torch.save(model.state_dict(), f'last_language_model_state_dict.pth')\n",
        "    torch.save(optimizer.state_dict(), 'last_optimizer_state_dict.pth')\n",
        "\n",
        "    with open(f'info_{n_epoch}.json', 'w') as file_object:\n",
        "\n",
        "        info = {\n",
        "            'message': message,\n",
        "            'train_losses': train_losses,\n",
        "            'validation_losses': validation_losses,\n",
        "            'train_perplexities': train_perplexities,\n",
        "            'validation_perplexities': validation_perplexities\n",
        "        }\n",
        "\n",
        "        file_object.write(json.dumps(info, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 9410/9410 [42:50<00:00,  3.66it/s, loss=6.13, perplexity=461]\n",
            "Evaluate: 100%|██████████| 495/495 [00:44<00:00, 11.07it/s, loss=5.94, perplexity=382]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Train: loss - 6.5967 | perplexity - 732.665\n",
            "Validation: loss - 5.9449 | perplexity - 381.802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 9410/9410 [42:41<00:00,  3.67it/s, loss=5.8, perplexity=331]\n",
            "Evaluate: 100%|██████████| 495/495 [00:44<00:00, 11.10it/s, loss=5.57, perplexity=263]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2\n",
            "Train: loss - 5.9224 | perplexity - 373.298\n",
            "Validation: loss - 5.5724 | perplexity - 263.062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 9410/9410 [42:40<00:00,  3.67it/s, loss=5.58, perplexity=265]\n",
            "Evaluate: 100%|██████████| 495/495 [00:44<00:00, 11.09it/s, loss=5.42, perplexity=225]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3\n",
            "Train: loss - 5.6764 | perplexity - 291.907\n",
            "Validation: loss - 5.4168 | perplexity - 225.164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 9410/9410 [42:45<00:00,  3.67it/s, loss=5.51, perplexity=248]\n",
            "Evaluate: 100%|██████████| 495/495 [00:44<00:00, 11.10it/s, loss=5.29, perplexity=199]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4\n",
            "Train: loss - 5.5313 | perplexity - 252.478\n",
            "Validation: loss - 5.2915 | perplexity - 198.647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 9410/9410 [42:43<00:00,  3.67it/s, loss=5.4, perplexity=222]\n",
            "Evaluate: 100%|██████████| 495/495 [00:44<00:00, 11.07it/s, loss=5.22, perplexity=184]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5\n",
            "Train: loss - 5.4332 | perplexity - 228.872\n",
            "Validation: loss - 5.2162 | perplexity - 184.239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvY1R9eZLTsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e98bb14-0ea9-4100-b653-5d4194cd4ea1"
      },
      "source": [
        "# подгружаем свою лучшую обученную модель\n",
        "model.load_state_dict(torch.load('best_language_model_state_dict.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4iDCVWCLTsj"
      },
      "source": [
        "## Генерируем продолжение текста aka \"Накидайте фото красивых песен\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQWmKw1pLTsj"
      },
      "source": [
        "def generate(seed_text, bos_index=2, eos_index=3, max_sequence=512):\n",
        "    \n",
        "    # мы используем какой-нибудь seed text для того, по нему предсказать продолжение\n",
        "    tokenized = tokenizer.encode([seed_text])\n",
        "    \n",
        "    # добавляем тег начала предложения\n",
        "    tokenized[0].insert(0, bos_index)\n",
        "    x = torch.tensor(tokenized).long().to(device)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # получим представления модели от нашего сид текста\n",
        "        emb = model.embedding_layer(x)\n",
        "\n",
        "        emb = model.embedding_dropout(emb)\n",
        "\n",
        "        lstm_out, mem = model.lstm(emb)\n",
        "\n",
        "        token_pred = model.language_model_head(lstm_out)\n",
        "\n",
        "        # семлируем последнее слово, что подать его на вход генератору\n",
        "        current_token = x[:, -1].unsqueeze(0)\n",
        "        \n",
        "        pred = []\n",
        "\n",
        "        # начинаем генерацию\n",
        "        # у нас есть текущий токен и mem от того, что мы уже предсказали\n",
        "        for timestamp in range(max_sequence):\n",
        "\n",
        "            emb = model.embedding_layer(current_token)\n",
        "\n",
        "            lstm_out, mem = model.lstm(emb, mem)\n",
        "\n",
        "            next_token_prediction = model.language_model_head(lstm_out)\n",
        "\n",
        "            pred.append(next_token_prediction)\n",
        "\n",
        "            current_token = next_token_prediction.argmax(dim=2)\n",
        "\n",
        "            # останавливаем генерировать текст, когда встретили токен конца предложения\n",
        "            if current_token == eos_index:\n",
        "                break\n",
        "\n",
        "        pred = torch.cat(pred, dim=1)\n",
        "\n",
        "    tokens = pred.argmax(dim=-1).detach().cpu().numpy()\n",
        "    predicted_text = tokenizer.decode(tokens.tolist())[0]\n",
        "    \n",
        "    return seed_text + ' ' + predicted_text[:predicted_text.index('<EOS>')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3X_Xj6LZLTsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51c196f-e642-4636-87c0-d66fc82f531a"
      },
      "source": [
        "# здесь мы задаем для нашей модели некоторое состояние, то есть некоторые первые слова\n",
        "# и модель должна продолжить сказанное\n",
        "\n",
        "# изначально здесь продолжения текстов, нагенерированные моделью, которая училась несколько часов\n",
        "# лосс в районе 4, перплексия примерно 55 и на чуть других данных\n",
        "# вы можете учить меньше\n",
        "seed_texts = [\n",
        "    'я',\n",
        "    'почему',\n",
        "    'зачем',\n",
        "    'мне',\n",
        "    'у меня болит',\n",
        "    'у меня',\n",
        "    'откуда',\n",
        "    'решите',\n",
        "    'я понимаю что вопрос странный но',\n",
        "    'какие бывают',\n",
        "    'стоит ли',\n",
        "    'нормально ли',\n",
        "    'что это',\n",
        "    'почему меня',\n",
        "    'кто',\n",
        "    'кто такой',\n",
        "    'что лучше',\n",
        "    'что могут сделать за',\n",
        "    'перечислите чем лучше',\n",
        "    'кто автор',\n",
        "    'как сделать',\n",
        "    'кто убил',\n",
        "    'накидайте',\n",
        "    'порекомендуйте',\n",
        "    'как правильно',\n",
        "    'что вы',\n",
        "    'что ты',\n",
        "    'зачем ты',\n",
        "    'почему ты',\n",
        "    'за что',\n",
        "    'с чем',\n",
        "    'с кем',\n",
        "    'почему она',\n",
        "    'почему он',\n",
        "    'я хочу',\n",
        "    'я хочу чтобы девушка',\n",
        "    'я хочу чтобы моя',\n",
        "    'я хочу чтобы моя девушка',\n",
        "    'мне нравится',\n",
        "    'почему она',\n",
        "    'зачем мне',\n",
        "    'что она',\n",
        "    'что он',\n",
        "    'зачем она',\n",
        "    'зачем он',\n",
        "    'как сделать так чтобы она',\n",
        "    'как сделать так чтобы он',\n",
        "    'как сделать так чтобы',\n",
        "    'моя девушка',\n",
        "    'мой парень',\n",
        "    'чем',\n",
        "    'кем',\n",
        "    'как'\n",
        "]\n",
        "\n",
        "for text in seed_texts:\n",
        "    print(f'Оригинальный текст: {text}')\n",
        "    print(f'Сгенерированное продолжение: {generate(text)}')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оригинальный текст: я\n",
            "Сгенерированное продолжение: я не знаю что делать\n",
            "\n",
            "Оригинальный текст: почему\n",
            "Сгенерированное продолжение: почему не работает интернет на телефоне\n",
            "\n",
            "Оригинальный текст: зачем\n",
            "Сгенерированное продолжение: зачем люди делают в интернете и в интернете не могут быть в россии и в россии и в россии\n",
            "\n",
            "Оригинальный текст: мне\n",
            "Сгенерированное продолжение: мне кажется что я не могу найти работу в интернете\n",
            "\n",
            "Оригинальный текст: у меня болит\n",
            "Сгенерированное продолжение: у меня болит голова\n",
            "\n",
            "Оригинальный текст: у меня\n",
            "Сгенерированное продолжение: у меня не было в жизни\n",
            "\n",
            "Оригинальный текст: откуда\n",
            "Сгенерированное продолжение: откуда взялось слово \"любовь\"?\n",
            "\n",
            "Оригинальный текст: решите\n",
            "Сгенерированное продолжение: решите задачу по физике\n",
            "\n",
            "Оригинальный текст: я понимаю что вопрос странный но\n",
            "Сгенерированное продолжение: я понимаю что вопрос странный но не знаю что делать\n",
            "\n",
            "Оригинальный текст: какие бывают\n",
            "Сгенерированное продолжение: какие бывают виды и виды в россии и в каком городе и в каком городе\n",
            "\n",
            "Оригинальный текст: стоит ли\n",
            "Сгенерированное продолжение: стоит ли покупать ps4 slim?\n",
            "\n",
            "Оригинальный текст: нормально ли\n",
            "Сгенерированное продолжение: нормально ли что у меня нет друзей на улице?\n",
            "\n",
            "Оригинальный текст: что это\n",
            "Сгенерированное продолжение: что это за вид кактуса?\n",
            "\n",
            "Оригинальный текст: почему меня\n",
            "Сгенерированное продолжение: почему меня не любят в этом году?\n",
            "\n",
            "Оригинальный текст: кто\n",
            "Сгенерированное продолжение: кто знает как называется этот цветок?\n",
            "\n",
            "Оригинальный текст: кто такой\n",
            "Сгенерированное продолжение: кто такой сон?\n",
            "\n",
            "Оригинальный текст: что лучше\n",
            "Сгенерированное продолжение: что лучше купить в пределах 500 рублей?\n",
            "\n",
            "Оригинальный текст: что могут сделать за\n",
            "Сгенерированное продолжение: что могут сделать за чёт в интернете?\n",
            "\n",
            "Оригинальный текст: перечислите чем лучше\n",
            "Сгенерированное продолжение: перечислите чем лучше всего хранить и не дорого и не дорого и не дорого и не дорого и не дорого\n",
            "\n",
            "Оригинальный текст: кто автор\n",
            "Сгенерированное продолжение: кто автор ского произведения\n",
            "\n",
            "Оригинальный текст: как сделать\n",
            "Сгенерированное продолжение: как сделать такой эффект в фотошопе\n",
            "\n",
            "Оригинальный текст: кто убил\n",
            "Сгенерированное продолжение: кто убил в мире\n",
            "\n",
            "Оригинальный текст: накидайте\n",
            "Сгенерированное продолжение: накидайте аниме про любовь\n",
            "\n",
            "Оригинальный текст: порекомендуйте\n",
            "Сгенерированное продолжение: порекомендуйте игры на андроид\n",
            "\n",
            "Оригинальный текст: как правильно\n",
            "Сгенерированное продолжение: как правильно написать заявление в суд на получение паспорта\n",
            "\n",
            "Оригинальный текст: что вы\n",
            "Сгенерированное продолжение: что вы можете сказать о человеке в этом году?\n",
            "\n",
            "Оригинальный текст: что ты\n",
            "Сгенерированное продолжение: что ты можешь сказать о своей женщине ?\n",
            "\n",
            "Оригинальный текст: зачем ты\n",
            "Сгенерированное продолжение: зачем ты любишь в своей жизни?)\n",
            "\n",
            "Оригинальный текст: почему ты\n",
            "Сгенерированное продолжение: почему ты любишь в своей жизни и не было ни разу не было ни разу не было ни разу не было ни разу не было ни разу не было ни разу не было ни разу не было ни разу не было ни разу не было ни разу не было\n",
            "\n",
            "Оригинальный текст: за что\n",
            "Сгенерированное продолжение: за что вы любите больше всего?)\n",
            "\n",
            "Оригинальный текст: с чем\n",
            "Сгенерированное продолжение: с чем можно носить такие очки?\n",
            "\n",
            "Оригинальный текст: с кем\n",
            "Сгенерированное продолжение: с кем можно работать в 14 лет?\n",
            "\n",
            "Оригинальный текст: почему она\n",
            "Сгенерированное продолжение: почему она не хочет общаться с девушками?\n",
            "\n",
            "Оригинальный текст: почему он\n",
            "Сгенерированное продолжение: почему он не хочет общаться с девушками?\n",
            "\n",
            "Оригинальный текст: я хочу\n",
            "Сгенерированное продолжение: я хочу стать актрисой\n",
            "\n",
            "Оригинальный текст: я хочу чтобы девушка\n",
            "Сгенерированное продолжение: я хочу чтобы девушка была в другом городе\n",
            "\n",
            "Оригинальный текст: я хочу чтобы моя\n",
            "Сгенерированное продолжение: я хочу чтобы моя подруга была в другом городе\n",
            "\n",
            "Оригинальный текст: я хочу чтобы моя девушка\n",
            "Сгенерированное продолжение: я хочу чтобы моя девушка сказала что я не хочу\n",
            "\n",
            "Оригинальный текст: мне нравится\n",
            "Сгенерированное продолжение: мне нравится парень, что делать?\n",
            "\n",
            "Оригинальный текст: почему она\n",
            "Сгенерированное продолжение: почему она не хочет общаться с девушками?\n",
            "\n",
            "Оригинальный текст: зачем мне\n",
            "Сгенерированное продолжение: зачем мне нужны эти часы?\n",
            "\n",
            "Оригинальный текст: что она\n",
            "Сгенерированное продолжение: что она чувствует к девушке?\n",
            "\n",
            "Оригинальный текст: что он\n",
            "Сгенерированное продолжение: что он делает?\n",
            "\n",
            "Оригинальный текст: зачем она\n",
            "Сгенерированное продолжение: зачем она мне так делает?\n",
            "\n",
            "Оригинальный текст: зачем он\n",
            "Сгенерированное продолжение: зачем он так делает?\n",
            "\n",
            "Оригинальный текст: как сделать так чтобы она\n",
            "Сгенерированное продолжение: как сделать так чтобы она не была в мире?\n",
            "\n",
            "Оригинальный текст: как сделать так чтобы он\n",
            "Сгенерированное продолжение: как сделать так чтобы он не мог меня найти\n",
            "\n",
            "Оригинальный текст: как сделать так чтобы\n",
            "Сгенерированное продолжение: как сделать так чтобы было в интернете было много денег и не могу найти\n",
            "\n",
            "Оригинальный текст: моя девушка\n",
            "Сгенерированное продолжение: моя девушка \n",
            "\n",
            "Оригинальный текст: мой парень\n",
            "Сгенерированное продолжение: мой парень \n",
            "\n",
            "Оригинальный текст: чем\n",
            "Сгенерированное продолжение: чем отличается отбор от обычного?\n",
            "\n",
            "Оригинальный текст: кем\n",
            "Сгенерированное продолжение: кем приходится двоюродный муж?\n",
            "\n",
            "Оригинальный текст: как\n",
            "Сгенерированное продолжение: как называется этот вид кактуса?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "yDk48y9RLTsk"
      },
      "source": [
        "# раскомментируйте, если хотите сами интерактивно пообщаться с моделью\n",
        "while True:\n",
        "    seed_text = input('Ваш текст: ')\n",
        "    if seed_text in ['стоп', 'хватит']:\n",
        "        break\n",
        "    print('Сгенерированный с продолжением: ', generate(seed_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A5foY9zLTsk"
      },
      "source": [
        "# Научились генерироваться вопросы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_MvbpL-LTsk"
      },
      "source": [
        "# Домашка №3\n",
        "## Seq2Seq\n",
        "### Научиться генерировать ответы по вопросу\n",
        "\n",
        "### Вам понадобится:\n",
        "1. Написать *Dataset* для задачи seq2seq\n",
        "1. Реализовать модель\n",
        "1. Сделать цикл обучения\n",
        "1. Реализовать метод генерации ответа по вопросу с помощью вашей модели\n",
        "\n",
        "### Примерный список того, что можно сделать:\n",
        "Необязательно реализовывать все\n",
        "1. Сделать модель, основанную на lstm/gru **5 баллов**\n",
        "1. Сделать модель, основанную на cnn **7 баллов**\n",
        "1. Сделать модель, основанную на трансформере (реализовать все слои самому) **10 баллов**\n",
        "1. Добавить в rnn/cnn модель attention **5 баллов**\n",
        "1. Реализовать жадное семплирование (генерацию по самому вероятному токену, как выше в языковой модели) **3 балла**\n",
        "1. Реализовать beam search **5 баллов**\n",
        "1. Реализовать nucleus sampling **5 баллов**\n",
        "1. Добавить condition в модель **3 балла**\n",
        "1. Добавить layer norm/residual в cnn или rnn модель **1 балл**\n",
        "1. Реализовать аккамуляцию градиентов **1 балл**\n",
        "1. Сделать телеграм бота **2 балла**\n",
        "\n",
        "#### Дополнительные детали:  \n",
        "**Сделать модель** подразумевает весь код с обучением и генерацией ответа по аналогии с языковой моделью.  \n",
        "**6-й пункт:** у нас есть категория вопроса и мы можем явным образом добавить эту информацию в модель. Затем мы сможем задавать вопрос из любой категории, а отвечать таким ответом, которой больше будет соответствовать категории (которую мы сможем сами задать в модель). То есть на этапе предсказания мы задаем сети вопрос и категорию ответа, то есть в каком стиле наша сеть должна ответить. То есть должно получиться что-то такое:\n",
        "```\n",
        "Вопрос пользователя:\n",
        "    Что мне делать с моей девушкой? она плохо себя ведет\n",
        "\n",
        "Задаем категорию:\n",
        "    Авто\n",
        "Ответ модели:\n",
        "    Сдайте ее в техосмотр\n",
        "\n",
        "Задаем категорию:\n",
        "    Сад и огород\n",
        "Ответ модели:\n",
        "    Вам нужно лучше ее поливать\n",
        "```\n",
        "**7-й пункт:**  \n",
        "Статья: https://arxiv.org/pdf/1904.09751.pdf  \n",
        "В помощь: https://huggingface.co/blog/how-to-generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qR1WXqeLTsl"
      },
      "source": [
        "### Данные для seq2seq\n",
        "***Данные*** - это файл, где каждая строка - json объект формата:\n",
        "```json\n",
        "{\n",
        "    \"question\": \"вопрос\",\n",
        "    \"category\": \"некоторая категория вопроса\",\n",
        "    \"responses\": [\n",
        "        \"первый ответ на вопрос\",\n",
        "        \"второй ответ на вопрос\",\n",
        "        \"третий ответ на вопрос\",\n",
        "    ]\n",
        "}\n",
        "```\n",
        "Количество ответов: от 1 до 5\n",
        "\n",
        "Эти данные лучше очищены, так что советую переобучить BPE.  \n",
        "Необязательно учиться на всех данных. Вы можете взять половину/четверть, если не хотите долго ждать. Так результаты будут похуже, но быстрее."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQxPrLsyLTsl",
        "outputId": "ec11cd68-d57f-45c0-c8e6-763756116ffc"
      },
      "source": [
        "qa_data = list()\n",
        "\n",
        "with open('qa_data.jsonl') as file_object:\n",
        "    for _ in range(5):\n",
        "        line = file_object.readline().strip()\n",
        "        \n",
        "        qa_data.append(json.loads(line))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'qa_data.jsonl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-2e8c47491ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqa_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qa_data.jsonl'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'qa_data.jsonl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qetU6lgelR6w"
      },
      "source": [
        "# Непосредственно домашка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibJ0DaKY5Ztm",
        "outputId": "186171c2-182e-4fc0-bb18-e417c8e40b45"
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\r\u001b[K     |▏                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 19.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 16.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 15.8MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 11.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 11.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 11.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 12.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 13.3MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 13.1MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 13.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122kB 13.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133kB 13.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143kB 13.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153kB 13.1MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204kB 13.1MB/s eta 0:00:01\r\u001b[K     |████                            | 215kB 13.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225kB 13.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235kB 13.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245kB 13.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 266kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 296kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 317kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 327kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 368kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 378kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 399kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 430kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 440kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 471kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 512kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 542kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 552kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 593kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 614kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 624kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 655kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 665kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 686kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 727kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 737kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 757kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 768kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 778kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 798kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 808kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 829kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 839kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 849kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 870kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 880kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 890kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 901kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 921kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 942kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 952kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 972kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 983kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 993kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.7MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuSnP5wd5T_N",
        "outputId": "c4da3622-0f34-4eac-dca2-088430f47088"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85XwARZ35g9X",
        "outputId": "b2077961-8352-4d7e-e047-efde0a0da425"
      },
      "source": [
        "!unzip /content/drive/MyDrive/dl_hw3/qa_data.jsonl.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/dl_hw3/qa_data.jsonl.zip\n",
            "  inflating: qa_data.jsonl           \n",
            "  inflating: __MACOSX/._qa_data.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq3KB55AlVPZ"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import youtokentome as yttm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfpsiIT_LTsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035db531-f000-459c-b980-635af4f7f4ba"
      },
      "source": [
        "# %%time\n",
        "# qa_data = list()\n",
        "\n",
        "# with open('qa_data.jsonl') as file_object:\n",
        "#     for line in file_object:\n",
        "#         qa_data.append(json.loads(line.strip()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 23.6 s, sys: 2.31 s, total: 25.9 s\n",
            "Wall time: 40 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsHLV5GAibtu",
        "outputId": "bdd753ab-d384-4cca-f77a-f9e990479761"
      },
      "source": [
        "# qa_data[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'category': 'Бизнес, Финансы',\n",
              "  'question': 'долго ли идут деньги с яндексденег на карту visa?',\n",
              "  'responses': ['нет. прорыв 35 ;)']},\n",
              " {'category': 'Авто, Мото',\n",
              "  'question': 'можно ли зарегистрировать авто в другом регионе',\n",
              "  'responses': ['можно на родственника из того региона.. .  а потом ездить по доверке']},\n",
              " {'category': 'Красота и Здоровье',\n",
              "  'question': 'что делать если у меня очень тонкие ногти а хочется их отрастить?',\n",
              "  'responses': ['витамины и умная эмаль (каждый день)',\n",
              "   'ванночки с морской солью. с вечера мажь ногти сверху йодом. не бойся, до утра все впитается.',\n",
              "   'умная эмаль, витамины, йод, и поменьше крась лаком ',\n",
              "   'лаки фирмы trind производство usa + кальций']},\n",
              " {'category': 'Спорт',\n",
              "  'question': 'в чем отличие медитации от йоги?',\n",
              "  'responses': ['букв в йоге меньше',\n",
              "   'в медитации ты просто сидишь и мммммычишь. а в йоге всяко разные упражнения вытворяешь',\n",
              "   'в медитации вроде просто тупо сидишь и успокаеваешься, а в йоге еще и ноги за уши закидывать надо']},\n",
              " {'category': 'Спорт',\n",
              "  'question': 'когда начнут линейку фильмов про лигу чемпионов?',\n",
              "  'responses': ['а не фильм? жалко... а я то думал - хорошая комедия']}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYvA7bDxrL4t",
        "outputId": "e727fe69-ecd2-456e-88a7-c5f01573b188"
      },
      "source": [
        "# %%time\n",
        "# questions = []\n",
        "# answers = []\n",
        "# categories = []\n",
        "\n",
        "# for d in tqdm(qa_data):\n",
        "#   for answer in d['responses']:\n",
        "#     questions.append(d['question'])\n",
        "#     answers.append(answer)\n",
        "#     categories.append(d['category'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2808811/2808811 [00:04<00:00, 665396.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.06 s, sys: 171 ms, total: 4.23 s\n",
            "Wall time: 4.22 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjjCB56F-e_b"
      },
      "source": [
        "# questions_shuffled, answers_shuffled, categories_shuffled = shuffle(questions, answers, categories)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB_UO-cvBMuI",
        "outputId": "343e36cc-ae12-4b8a-9f69-c7681e59d6a8"
      },
      "source": [
        "# questions_shuffled[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['вопрос тем, кто недавно делал ремонт. какие у вас полы? долго настилали? довольны качеством? есть ли минусы?',\n",
              " 'чем встретит спартак,ростов-папа ? 19:30 ростов - спартак м угадайте итог матча ?',\n",
              " 'как избавиться от \"тупой\" боли в затылке?',\n",
              " 'почему если пара вместе 5 лет и больше все думают что это привычка?',\n",
              " 'какой то прыщик, или свищ, подскажите к какому врачу идти ?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C82GVgDwBOuu",
        "outputId": "642065a4-07ef-49be-9e20-9dce695956d8"
      },
      "source": [
        "# answers_shuffled[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['делал. на пол стелил ламинат. доволен. минусы? если даже ручка падает на пол - звук громкий.',\n",
              " '0:0 или 1:1 )',\n",
              " 'шесть золотых правил здоровья кацудзо ниши. посмотри в ютубе майю гогулан. через 3 дня будет всё в порядке.',\n",
              " 'отнимите от всех окружающих мой голос: я так не думаю..',\n",
              " 'с хирургом проконсультируйся для начала']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8if5Mv62BROu",
        "outputId": "ee3a16e3-0d6e-4ea9-c46c-b3b33fdee65d"
      },
      "source": [
        "# categories_shuffled[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Семья, Дом, Дети',\n",
              " 'Спорт',\n",
              " 'Красота и Здоровье',\n",
              " 'Семья, Дом, Дети',\n",
              " 'Красота и Здоровье']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYewXzEpBbiv"
      },
      "source": [
        "# questions, answers, categories = questions_shuffled[:4_000_000], answers_shuffled[:4_000_000], categories_shuffled[:4_000_000]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CUTVaBp_GrK"
      },
      "source": [
        "# qas = pd.DataFrame({\"questions\": questions,\n",
        "#                     \"answers\": answers,\n",
        "#                     \"categories\": categories})\n",
        "# qas.to_csv('/content/drive/MyDrive/dl_hw3/qas.csv', index=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N96yHwx_ayy"
      },
      "source": [
        "qas = pd.read_csv('/content/drive/MyDrive/dl_hw3/qas.csv')\n",
        "qas = qas[:3_000_000]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zkBYOjUVB1lk",
        "outputId": "c7db06bc-9e5a-4b94-9830-ed001ec33129"
      },
      "source": [
        "qas.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>вопрос тем, кто недавно делал ремонт. какие у ...</td>\n",
              "      <td>делал. на пол стелил ламинат. доволен. минусы?...</td>\n",
              "      <td>Семья, Дом, Дети</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>чем встретит спартак,ростов-папа ? 19:30 росто...</td>\n",
              "      <td>0:0 или 1:1 )</td>\n",
              "      <td>Спорт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>как избавиться от \"тупой\" боли в затылке?</td>\n",
              "      <td>шесть золотых правил здоровья кацудзо ниши. по...</td>\n",
              "      <td>Красота и Здоровье</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>почему если пара вместе 5 лет и больше все дум...</td>\n",
              "      <td>отнимите от всех окружающих мой голос: я так н...</td>\n",
              "      <td>Семья, Дом, Дети</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>какой то прыщик, или свищ, подскажите к какому...</td>\n",
              "      <td>с хирургом проконсультируйся для начала</td>\n",
              "      <td>Красота и Здоровье</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           questions  ...          categories\n",
              "0  вопрос тем, кто недавно делал ремонт. какие у ...  ...    Семья, Дом, Дети\n",
              "1  чем встретит спартак,ростов-папа ? 19:30 росто...  ...               Спорт\n",
              "2          как избавиться от \"тупой\" боли в затылке?  ...  Красота и Здоровье\n",
              "3  почему если пара вместе 5 лет и больше все дум...  ...    Семья, Дом, Дети\n",
              "4  какой то прыщик, или свищ, подскажите к какому...  ...  Красота и Здоровье\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtJUYrVBB0pA"
      },
      "source": [
        "questions = qas.questions.values\n",
        "answers = qas.answers.values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaU6CVlL-m0G",
        "outputId": "990fac4c-337f-4f94-c0af-f314c2f60416"
      },
      "source": [
        "questions[:5], answers[:5]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['вопрос тем, кто недавно делал ремонт. какие у вас полы? долго настилали? довольны качеством? есть ли минусы?',\n",
              "        'чем встретит спартак,ростов-папа ? 19:30 ростов - спартак м угадайте итог матча ?',\n",
              "        'как избавиться от \"тупой\" боли в затылке?',\n",
              "        'почему если пара вместе 5 лет и больше все думают что это привычка?',\n",
              "        'какой то прыщик, или свищ, подскажите к какому врачу идти ?'],\n",
              "       dtype=object),\n",
              " array(['делал. на пол стелил ламинат. доволен. минусы? если даже ручка падает на пол - звук громкий.',\n",
              "        '0:0 или 1:1 )',\n",
              "        'шесть золотых правил здоровья кацудзо ниши. посмотри в ютубе майю гогулан. через 3 дня будет всё в порядке.',\n",
              "        'отнимите от всех окружающих мой голос: я так не думаю..',\n",
              "        'с хирургом проконсультируйся для начала'], dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwGUIVpaVk2T"
      },
      "source": [
        "## BPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sSOZKOAcdgU"
      },
      "source": [
        "Переобучим BPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48ZdR6u8cc-X"
      },
      "source": [
        "# with open('/content/drive/MyDrive/dl_hw3/for_new_bpe.txt', 'w', encoding='utf-8') as f:\n",
        "#   for one_dict in qa_data:\n",
        "#     f.write(one_dict['question'] + '\\n')\n",
        "#     for answer in one_dict['responses']:\n",
        "#       f.write(answer + '\\n')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_bhQXijccj2",
        "outputId": "f13a21e8-953a-4b00-9c5f-ed5aaabc9746"
      },
      "source": [
        "# %%time\n",
        "# data_path = '/content/drive/MyDrive/dl_hw3/for_new_bpe.txt'\n",
        "# yttm.BPE.train(data=data_path, vocab_size=vocab_size, model=model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 4s, sys: 6.03 s, total: 1min 10s\n",
            "Wall time: 1min 9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<youtokentome.youtokentome.BPE at 0x7f6499f3d5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkX3VL6FDSs1"
      },
      "source": [
        "vocab_size = 100_000\n",
        "model_path = '/content/drive/MyDrive/dl_hw3/new_pretrained_bpe_lm.model'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80-dVkLKmCiL"
      },
      "source": [
        "tokenizer = yttm.BPE(model=model_path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qhmBw82q-6N"
      },
      "source": [
        "tokenized_questions = []\n",
        "tokenized_answers = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWR7BGj18K14",
        "outputId": "e5a5bfb4-0672-4c9b-aa92-6140ef4f6f3b"
      },
      "source": [
        "%%time\n",
        "for q in tqdm(questions):\n",
        "  tokenized_questions.append(tokenizer.encode(q, bos=True, eos=True))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000000/3000000 [00:40<00:00, 73604.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39.8 s, sys: 1.04 s, total: 40.8 s\n",
            "Wall time: 40.8 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLl9-Q668fKn",
        "outputId": "97bc9491-053d-4b19-88ea-dc1a18fd81f1"
      },
      "source": [
        "%%time\n",
        "for a in tqdm(answers):\n",
        "  tokenized_answers.append(tokenizer.encode(a, bos=True, eos=True))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000000/3000000 [00:38<00:00, 77867.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 37.6 s, sys: 985 ms, total: 38.6 s\n",
            "Wall time: 38.5 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8XT9jSiGE6c",
        "outputId": "bbc9ac6c-55ad-4d6a-b785-303c02fbc218"
      },
      "source": [
        "lengths = np.array([len(x) for x in tokenized_questions])\n",
        "np.percentile(lengths, q=99)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_C6XNFeGI1f",
        "outputId": "ce4dcd47-d922-4498-c0f8-49ad1fc9dec2"
      },
      "source": [
        "lengths = np.array([len(x) for x in tokenized_answers])\n",
        "np.percentile(lengths, q=99)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYbVff2uGSuO",
        "outputId": "361bc017-9c7c-426f-8ae5-6413543206db"
      },
      "source": [
        "tokenized_questions[:2]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2,\n",
              "  1102,\n",
              "  4047,\n",
              "  916,\n",
              "  3850,\n",
              "  6871,\n",
              "  32341,\n",
              "  1143,\n",
              "  738,\n",
              "  1052,\n",
              "  714,\n",
              "  9880,\n",
              "  1989,\n",
              "  32306,\n",
              "  736,\n",
              "  1819,\n",
              "  16700,\n",
              "  5514,\n",
              "  1594,\n",
              "  888,\n",
              "  832,\n",
              "  34051,\n",
              "  3],\n",
              " [2,\n",
              "  986,\n",
              "  80463,\n",
              "  24682,\n",
              "  718,\n",
              "  3121,\n",
              "  8401,\n",
              "  829,\n",
              "  1025,\n",
              "  2179,\n",
              "  18475,\n",
              "  12162,\n",
              "  799,\n",
              "  4769,\n",
              "  715,\n",
              "  10830,\n",
              "  28925,\n",
              "  7297,\n",
              "  1025,\n",
              "  3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boFqtd5smG8o"
      },
      "source": [
        "## Датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BSFSrD6VnQj"
      },
      "source": [
        "class AnswerGenerationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, questions, answers, max_len, pad_index=0):\n",
        "        \n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "        \n",
        "        self.max_len = max_len\n",
        "        \n",
        "        self.pad_index = pad_index\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "    \n",
        "    def padding(self, text):\n",
        "\n",
        "        pads = [self.pad_index] * (self.max_len - len(text))\n",
        "        return text + pads\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        question = self.questions[index][:self.max_len]\n",
        "        answer = self.answers[index][:self.max_len]\n",
        "        \n",
        "        question = self.padding(question)\n",
        "        answer = self.padding(answer)\n",
        "        \n",
        "        question = torch.tensor(question).long()\n",
        "        answer = torch.tensor(answer).long()\n",
        "        \n",
        "        return question, answer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNT_cj_mDsAF"
      },
      "source": [
        "train_dataset = AnswerGenerationDataset(questions=tokenized_questions[:2_900_000], answers=tokenized_answers[:2_900_000], max_len=30)\n",
        "valid_dataset = AnswerGenerationDataset(questions=tokenized_questions[2_900_000:], answers=tokenized_answers[2_900_000:], max_len=30)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiBBRFNiDsaQ"
      },
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mli-FXOSEetO",
        "outputId": "3e03d66a-5ee9-476b-d6ef-85ca0a5227c3"
      },
      "source": [
        "x"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2,   758,   895,  ...,     0,     0,     0],\n",
              "        [    2,   850,   758,  ...,     0,     0,     0],\n",
              "        [    2,   792,   787,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2,   792, 12736,  ...,     0,     0,     0],\n",
              "        [    2,  1232, 15128,  ...,     0,     0,     0],\n",
              "        [    2,   792, 16940,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRH56j-5Ef6i",
        "outputId": "c65b5d59-b7a1-4f17-941e-d4b0d7a16a9b"
      },
      "source": [
        "y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2,   802, 15028,  ...,     0,     0,     0],\n",
              "        [    2,  1130, 58654,  ...,     0,     0,     0],\n",
              "        [    2,   725,  2261,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2, 18416,  7937,  ...,     0,     0,     0],\n",
              "        [    2,  3006,   949,  ...,     0,     0,     0],\n",
              "        [    2,  6045,  3456,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk6ZZMzuQUMi"
      },
      "source": [
        "## Модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU272tkQQWeu"
      },
      "source": [
        "assert torch.cuda.is_available()\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzStk2n6Rxcm"
      },
      "source": [
        "class SpatialDropout(torch.nn.Dropout2d):\n",
        "    \n",
        "    def __init__(self, p=0.3):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)\n",
        "        x = x.permute(0, 3, 2, 1)\n",
        "        x = super(SpatialDropout, self).forward(x)\n",
        "        x = x.permute(0, 3, 2, 1)\n",
        "        x = x.squeeze(2)\n",
        "        return x"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gLjQdB5SBPY"
      },
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, model_dim, num_layers,\n",
        "                 padding_idx=0, dropout=0.35, weight_tying=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size,\n",
        "                                                  embedding_dim=embedding_dim, padding_idx=padding_idx)\n",
        "        \n",
        "        self.embedding_dropout = SpatialDropout(p=dropout)\n",
        "        \n",
        "        self.lstm = torch.nn.LSTM(input_size=embedding_dim, hidden_size=model_dim, \n",
        "                                  num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        \n",
        "        self.language_model_head = torch.nn.Linear(in_features=model_dim, out_features=vocab_size, bias=False)\n",
        "        \n",
        "        # как раз здесь задаем, чтобы веса входящего и выходящего слоя эмбеддингов шарились\n",
        "        if weight_tying and embedding_dim == model_dim:\n",
        "            self.language_model_head.weight = self.embedding_layer.weight\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.embedding_layer(x)\n",
        "        \n",
        "        x = self.embedding_dropout(x)\n",
        "        \n",
        "        x, _ = self.lstm(x)\n",
        "        \n",
        "        x = self.language_model_head(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lz3-yGVlMWY"
      },
      "source": [
        "embedding_dim = 512\n",
        "model_dim = 512\n",
        "num_layers = 3"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exUxw8b9k76Z",
        "outputId": "ef852f8a-832e-4686-e584-a052e682a4df"
      },
      "source": [
        "model = LanguageModel(vocab_size=vocab_size, \n",
        "                      embedding_dim=embedding_dim, \n",
        "                      model_dim=model_dim, \n",
        "                      num_layers=num_layers)\n",
        "model.to(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding_layer): Embedding(100000, 512, padding_idx=0)\n",
              "  (embedding_dropout): SpatialDropout(p=0.35, inplace=False)\n",
              "  (lstm): LSTM(512, 512, num_layers=3, batch_first=True, dropout=0.35)\n",
              "  (language_model_head): Linear(in_features=512, out_features=100000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcwtIl8bQrFa"
      },
      "source": [
        "## Обучение и валидация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so0YrWORQt_8"
      },
      "source": [
        "def train_model(model, train_loader, optimizer, criterion, n_epoch, clip=3.0):\n",
        "\n",
        "    train_losses = list()\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    train_progress_bar = tqdm(total=len(train_loader.dataset), desc=f'Epoch: {n_epoch + 1}, train')\n",
        "    \n",
        "    for instance in list(tqdm._instances):\n",
        "      tqdm._decr_instances(instance)\n",
        "\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "            \n",
        "        pred = model(x)\n",
        "        \n",
        "        loss = criterion(pred.view(-1, pred.size(-1)), y.view(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        train_progress_bar.set_postfix(train_loss = np.mean(train_losses[-500:]))\n",
        "        train_progress_bar.update(x.shape[0])\n",
        "\n",
        "    train_progress_bar.close()\n",
        "\n",
        "    return train_losses"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsoCTMrQvtd"
      },
      "source": [
        "def validate_model(model, valid_loader, optimizer, criterion, n_epoch):\n",
        "\n",
        "    valid_losses = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    valid_progress_bar = tqdm(total=len(valid_loader.dataset), desc=f'Epoch: {n_epoch + 1}, validation')\n",
        "\n",
        "    for instance in list(tqdm._instances):\n",
        "      tqdm._decr_instances(instance)\n",
        "\n",
        "    for x, y in valid_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():  \n",
        "            pred = model(x)\n",
        "       \n",
        "        loss = criterion(pred.view(-1, pred.size(-1)), y.view(-1))\n",
        "\n",
        "        valid_losses.append(loss.item())\n",
        "\n",
        "        valid_progress_bar.set_postfix(valid_loss = np.mean(valid_losses[-500:]))\n",
        "        valid_progress_bar.update(x.shape[0])\n",
        "    \n",
        "    valid_progress_bar.close()\n",
        "\n",
        "    return valid_losses"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "TeCbHqiVQzQX",
        "outputId": "bd503582-d820-43a1-88c6-4e72e8e69b16"
      },
      "source": [
        "%%time\n",
        "# заложить 6 часов на обучение\n",
        "best_val_loss = 10.\n",
        "losses = list()\n",
        "val_losses = list()\n",
        "tr_losses = list()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "for n_epoch in range(3):\n",
        "\n",
        "  epoch_train_losses = train_model(model, train_loader, optimizer, criterion, n_epoch)\n",
        "  epoch_valid_losses = validate_model(model, valid_loader, optimizer, criterion, n_epoch)\n",
        "  \n",
        "  for l in epoch_train_losses:\n",
        "    losses.append(l)\n",
        "\n",
        "  mean_epoch_val_loss = np.mean(epoch_valid_losses)\n",
        "  mean_epoch_train_loss = np.mean(epoch_train_losses)\n",
        "\n",
        "  val_losses.append(mean_epoch_val_loss)\n",
        "  tr_losses.append(mean_epoch_train_loss)\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  if mean_epoch_val_loss < best_val_loss:\n",
        "    best_val_loss = mean_epoch_val_loss\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/dl_hw3/best_model_state_dict.pth')\n",
        "    torch.save(optimizer.state_dict(), '/content/drive/MyDrive/dl_hw3/best_optimizer_state_dict.pth')\n",
        "  else:\n",
        "    # убрала early stopping, чтобы дать модели дообучиться до лучшего результата\n",
        "    print(f'Early stopping on epoch {n_epoch+1}')\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/dl_hw3/last_model_state_dict.pth')\n",
        "    torch.save(optimizer.state_dict(), '/content/drive/MyDrive/dl_hw3/last_optimizer_state_dict.pth')\n",
        "    break"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, train:  35%|███▍      | 1004672/2900000 [57:13<1:47:57, 292.59it/s, train_loss=7.61]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-05e50dc442a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_val_loss = 10.\\nlosses = list()\\nval_losses = list()\\ntr_losses = list()\\n\\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=0)\\noptimizer = torch.optim.Adam(params=model.parameters())\\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)\\n\\nfor n_epoch in range(2):\\n\\n  epoch_train_losses = train_model(model, train_loader, optimizer, criterion, n_epoch)\\n  epoch_valid_losses = validate_model(model, valid_loader, optimizer, criterion, n_epoch)\\n  \\n  for l in epoch_train_losses:\\n    losses.append(l)\\n\\n  mean_epoch_val_loss = np.mean(epoch_valid_losses)\\n  mean_epoch_train_loss = np.mean(epoch_train_losses)\\n\\n  val_losses.append(mean_epoch_val_loss)\\n  tr_losses.append(mean_epoch_train_loss)\\n\\n  scheduler.step()\\n\\n  if mean_epoch_val_loss < best_val_loss:\\n    best_val_loss = mean_epoch_val_loss\\n    torch.save(model.state_dict(), f'best_model_state_dict.pth')\\n    torch.save(optimizer.state_dict(), 'best_optimizer_state_dict.pth')\\n  else:\\n    # убрала early stopping, чтобы дать модели дообучиться до лучшего результата\\n    print(f'Early stopping on epoch {n_epoch+1}')\\n    torch.save(model.state_dict(), f'last_model_state_dict.pth')\\n    torch.save(optimizer.state_dict(), 'last_optimizer_state_dict.pth')\\n    break\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-632189bc6ee0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion, n_epoch, clip)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gE0wGRv2Pqo"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/dl_hw3/best_model_state_dict.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xnip-bORPnd"
      },
      "source": [
        "## Генерация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wItaGYwRTdD"
      },
      "source": [
        "def generate_answer(question, model=model, bos_index=2, eos_index=3, max_sequence=512):\n",
        "    \n",
        "    # мы используем какой-нибудь seed text для того, по нему предсказать продолжение\n",
        "    tokenized = tokenizer.encode([question], bos=True, eos=True)\n",
        "    \n",
        "    # добавляем тег начала предложения\n",
        "    # tokenized[0].insert(0, bos_index)\n",
        "    x = torch.tensor(tokenized).long().to(device)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # # получим представления модели от нашего сид текста\n",
        "        # emb = model.embedding_layer(x)\n",
        "\n",
        "        # emb = model.embedding_dropout(emb)\n",
        "\n",
        "        # lstm_out, mem = model.lstm(emb)\n",
        "\n",
        "        # token_pred = model.language_model_head(lstm_out)\n",
        "        token_pred = model.forward(x)\n",
        "        # семлируем последнее слово, что подать его на вход генератору\n",
        "        current_token = x[:, -1].unsqueeze(0)\n",
        "        \n",
        "        pred = []\n",
        "\n",
        "        # начинаем генерацию\n",
        "        # у нас есть текущий токен и mem от того, что мы уже предсказали\n",
        "        for timestamp in range(max_sequence):\n",
        "\n",
        "            emb = model.embedding_layer(current_token)\n",
        "\n",
        "            lstm_out, mem = model.lstm(emb, mem)\n",
        "\n",
        "            next_token_prediction = model.language_model_head(lstm_out)\n",
        "\n",
        "            pred.append(next_token_prediction)\n",
        "\n",
        "            current_token = next_token_prediction.argmax(dim=2)\n",
        "\n",
        "            # останавливаем генерировать текст, когда встретили токен конца предложения\n",
        "            if current_token == eos_index:\n",
        "                break\n",
        "\n",
        "        pred = torch.cat(pred, dim=1)\n",
        "\n",
        "    tokens = pred.argmax(dim=-1).detach().cpu().numpy()\n",
        "    predicted_text = tokenizer.decode(tokens.tolist())[0]\n",
        "    \n",
        "    return predicted_text[:predicted_text.index('<EOS>')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B30_k7er0hO"
      },
      "source": [
        "my_questions = [\n",
        "    'почему пингвины не летают?',\n",
        "    'зачем киту фонтан?',\n",
        "    'что делать, если у меня коронавирус?',\n",
        "    'у меня болит живот, я умру?',\n",
        "    'откуда пришла саранча?',\n",
        "    'я понимаю что вопрос странный но где живут белки?',\n",
        "    'какие бывают коты?',\n",
        "    'стоит ли идти учиться на компьютерного лингвиста?',\n",
        "    'нормально ли ходить в школу?',\n",
        "    'почему меня не пускают без сменки?',\n",
        "    'кто такой ленин?',\n",
        "    'кто такой сталин?',\n",
        "    'что лучше моржи или еноты?',\n",
        "    'кто автор горя от ума?',\n",
        "    'как твои дела?',\n",
        "    'кто убил старуху-процентщицу?',\n",
        "    'накидайте бредовых вопросов для приколюх с нейронкой',\n",
        "    'порекомендуйте какие овощи есть на третьи лунные сутки',\n",
        "    'как правильно говорить: левиоса или левиоса?',\n",
        "    'что вы думаете о короне?',\n",
        "    'что ты знаешь о сериалах?',\n",
        "    'зачем ты наступаешь на одни и те же грабли?',\n",
        "    'почему ты любишь песни Стинга?']\n",
        "#     ,\n",
        "#     'за что',\n",
        "#     'с чем',\n",
        "#     'с кем',\n",
        "#     'почему она',\n",
        "#     'почему он',\n",
        "#     'я хочу',\n",
        "#     'я хочу чтобы девушка',\n",
        "#     'я хочу чтобы моя',\n",
        "#     'я хочу чтобы моя девушка',\n",
        "#     'мне нравится',\n",
        "#     'почему она',\n",
        "#     'зачем мне',\n",
        "#     'что она',\n",
        "#     'что он',\n",
        "#     'зачем она',\n",
        "#     'зачем он',\n",
        "#     'как сделать так чтобы она',\n",
        "#     'как сделать так чтобы он',\n",
        "#     'как сделать так чтобы',\n",
        "#     'моя девушка',\n",
        "#     'мой парень',\n",
        "#     'чем',\n",
        "#     'кем',\n",
        "#     'как'\n",
        "# ]\n",
        "\n",
        "for qu in my_questions:\n",
        "    print(f'Вопрос: {qu}')\n",
        "    print(f'Ответ: {generate_answer(qu)}')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUnNC4rlSX96"
      },
      "source": [
        "while True:\n",
        "    your_question = input('Ваш вопрос: ')\n",
        "    if your_question in ['стоп', 'хватит']:\n",
        "        break\n",
        "    print('Ответ от модели: ', generate_answer(your_question))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRURRqGr22ub"
      },
      "source": [
        "def show_losses_graph(losses, training=True, epoch=True):\n",
        "  plt.figure(figsize=(7, 7))\n",
        "  plt.plot(losses)\n",
        "  plt.grid()\n",
        "  if training:\n",
        "    plt.title('Training process')\n",
        "  else:\n",
        "    plt.title('Validation process')\n",
        "  if epoch:\n",
        "    plt.xlabel('Epochs')\n",
        "  else:\n",
        "    plt.xlabel('Iterations')\n",
        "  plt.ylabel('Loss function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B633GgYE2470"
      },
      "source": [
        "show_losses_graph(losses, epoch=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00T-yzRQ26RL"
      },
      "source": [
        "show_losses_graph(tr_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH5Bx24K27p0"
      },
      "source": [
        "show_losses_graph(val_losses, training=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}